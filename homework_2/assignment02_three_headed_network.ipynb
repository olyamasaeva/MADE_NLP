{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13pL--6rycN3"
   },
   "source": [
    "## Homework02: Three headed network in PyTorch\n",
    "\n",
    "This notebook accompanies the [week02](https://github.com/girafe-ai/natural-language-processing/tree/master/week02_cnn_for_texts) practice session. Refer to that notebook for more comments.\n",
    "\n",
    "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8zS7m-gycN5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run this cell, if you don't have data locally yet.\n",
    "\n",
    "#!curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
    "#!tar -xvzf ./Train_rev1.csv.tar.gz\n",
    "\n",
    "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
    "\n",
    "# !wget https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "vwN72gd4ycOA",
    "outputId": "7b9e8549-3128-4041-c4be-33fb6f326c78"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../week02_CNN_n_Vanishing_gradient/Train_rev1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# run this cell if you have downloaded the dataset on the seminar\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m../../week02_CNN_n_Vanishing_gradient/Train_rev1.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, index_col\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../week02_CNN_n_Vanishing_gradient/Train_rev1.csv'"
     ]
    }
   ],
   "source": [
    "# run this cell if you have downloaded the dataset on the seminar\n",
    "data = pd.read_csv(\"../../week02_CNN_n_Vanishing_gradient/Train_rev1.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "UuuKIKfrycOH",
    "outputId": "e5de0f94-a4f6-4b51-db80-9d11ddc1db31"
   },
   "outputs": [],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "data.sample(3)\n",
    "\n",
    "\n",
    "data_for_autotest = data[-5000:]\n",
    "data = data[:-5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUWkpd7PycOQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239768it [02:17, 1742.16it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "# see task above\n",
    "def normalize(text):\n",
    "    text = str(text).lower()\n",
    "    return ' '.join(tokenizer.tokenize(text))\n",
    "    \n",
    "data[text_columns] = data[text_columns].applymap(normalize)\n",
    "\n",
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
    "\n",
    "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
    "# build a dictionary { token -> it's count }\n",
    "from collections import Counter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "token_counts = Counter()# <YOUR CODE HERE>\n",
    "for _, row in tqdm(data[text_columns].iterrows()):\n",
    "    for string in row:\n",
    "        token_counts.update(string.split())\n",
    "\n",
    "# hint: you may or may not want to use collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2598827"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts.most_common(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "GiOWbc15ycOb",
    "outputId": "1e807140-5513-4af0-d9a9-9f029059a553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 201127\n",
      "('and', 2598827)\n",
      "('.', 2471477)\n",
      "(',', 2266256)\n",
      "('the', 2036428)\n",
      "('to', 1977039)\n",
      "...\n",
      "('dbms_stats', 1)\n",
      "('dbms_output', 1)\n",
      "('dbms_job', 1)\n",
      "Correct!\n",
      "Vocabulary size: 33795\n",
      "Correct!\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')\n",
    "\n",
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Vocabulary size:\", len(tokens))\n",
    "\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")\n",
    "\n",
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEsLeBjVycOw"
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "JiBlPkdKycOy",
    "outputId": "3866b444-1e2d-4d79-d429-fecc6d8e02a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[10705 29830  2143     1     1]\n",
      " [14875  2817     1     1     1]\n",
      " [27345 10107    15 15069 10702]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "DpOlBp7ZycO6",
    "outputId": "30a911f2-7d35-4cb5-8991-60457b1e8bac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yk4jmtAYycO8"
   },
   "source": [
    "### The deep learning part\n",
    "\n",
    "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
    "\n",
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
    "\n",
    "\n",
    "#### Here comes the simple one-headed network from the seminar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "TngLcWA0ycO_",
    "outputId": "6731b28c-07b1-41dc-9574-f76b01785bba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  191814\n",
      "Validation size =  47954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PXuKgOSycPB"
   },
   "outputs": [],
   "source": [
    "def make_batch(data, max_len=None, word_dropout=0):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "I6LpEQf0ycPD",
    "outputId": "e3520cae-fba1-46cc-a216-56287b6e4929"
   },
   "outputs": [],
   "source": [
    "a = make_batch(data_train[:3], max_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need these to make it simple\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Reorder(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.permute((0, 2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate minibatches we will use simple pyton generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            target = batch.pop(target_column)\n",
    "            yield batch, target\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iterate_minibatches(data_train, 3)\n",
    "batch, target = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is some startup code:\n",
    "n_tokens=len(tokens)\n",
    "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
    "hid_size=64\n",
    "simple_model = nn.Sequential()\n",
    "\n",
    "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
    "simple_model.add_module('reorder', Reorder())\n",
    "simple_model.add_module('conv1', nn.Conv1d(\n",
    "    in_channels=hid_size,\n",
    "    out_channels=hid_size,\n",
    "    kernel_size=2)\n",
    "                       )\n",
    "simple_model.add_module('relu1', nn.ReLU())\n",
    "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
    "simple_model.add_module('flatten1', Flatten())\n",
    "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
    "# <YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': array([[ 8114, 27445,  1569,     1,     1],\n",
       "        [29561, 26982, 30073, 15402, 11077],\n",
       "        [10705, 27943, 18670,     1,     1]]),\n",
       " 'FullDescription': array([[  307, 19941,  7338, ...,     1,     1,     1],\n",
       "        [  965, 30069, 33010, ..., 21972,  7253,   167],\n",
       "        [10705, 27943, 18670, ...,     1,     1,     1]]),\n",
       " 'Categorical': array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remember!__ We are working with regression problem and predicting only one number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0891],\n",
       "        [-0.0948],\n",
       "        [-0.1627]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
    "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 314)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['FullDescription'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " from IPython.display import clear_output\n",
    " from random import sample\n",
    "\n",
    " epochs = 1\n",
    "\n",
    " model = simple_model\n",
    " opt = torch.optim.Adam(model.parameters())\n",
    " loss_func = nn.MSELoss()\n",
    "\n",
    " history = []\n",
    " for epoch_num in range(epochs):\n",
    "     for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
    "         # Preprocessing the batch data and target\n",
    "         batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
    "\n",
    "         target = torch.tensor(target)\n",
    "\n",
    "\n",
    "         predictions = model(batch)\n",
    "         predictions = predictions.view(predictions.size(0))\n",
    "\n",
    "         loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
    "\n",
    "         # train with backprop\n",
    "         loss.backward()\n",
    "         opt.step()\n",
    "         opt.zero_grad()\n",
    "#         # <YOUR CODE HERE>\n",
    "\n",
    "         history.append(loss.data.numpy())\n",
    "         if (idx+1)%10==0:\n",
    "             clear_output(True)\n",
    "             plt.plot(history,label='loss')\n",
    "             plt.legend()\n",
    "             plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual homework starts here\n",
    "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
    "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eI5h9UMycPF"
   },
   "source": [
    "#### Architecture\n",
    "\n",
    "Our main model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
    "\n",
    "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'network' from 'c:\\\\Users\\\\user\\\\Desktop\\\\made\\\\nlp\\\\assignments\\\\network.py'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run this cell if you updated the file with network source code\n",
    "import imp\n",
    "imp.reload(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network.ThreeInputsNet(\n",
    "    n_tokens=len(tokens),\n",
    "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
    "\n",
    "    # this parameter defines the number of the inputs in the layer,\n",
    "    # which stands after the concatenation. In should be found out by you.\n",
    "    concat_number_of_features = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
    "testing_batch = [\n",
    "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['Categorical'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine!\n"
     ]
    }
   ],
   "source": [
    "assert model(testing_batch).shape == torch.Size([3, 1])\n",
    "assert model(testing_batch).dtype == torch.float32\n",
    "print('Seems fine!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the network for a while (100 batches would be fine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m epoch_num \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m     11\u001b[0m     \u001b[39mfor\u001b[39;00m idx, (batch, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(iterate_minibatches(data_train)):\n\u001b[0;32m     12\u001b[0m         \u001b[39m# Preprocessing the batch data and target\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m         batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(batch, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mlong)\n\u001b[0;32m     16\u001b[0m         target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(target)\n\u001b[0;32m     19\u001b[0m         predictions \u001b[39m=\u001b[39m model(batch)\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required (got type dict)"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output \n",
    "from random import sample\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "history = []\n",
    "for epoch_num in range(epochs):\n",
    "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
    "        # Preprocessing the batch data and target\n",
    "        print(batch)\n",
    "        batch = torch.tensor(batch, dtype=torch.long)\n",
    "\n",
    "        target = torch.tensor(target)\n",
    "\n",
    "\n",
    "        predictions = model(batch)\n",
    "        predictions = predictions.view(predictions.size(0))\n",
    "\n",
    "        loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
    "\n",
    "        # train with backprop\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "#         # <YOUR CODE HERE>\n",
    "\n",
    "        history.append(loss.data.numpy())\n",
    "        if (idx+1)%10==0:\n",
    "            clear_output(True)\n",
    "            plt.plot(history,label='loss')\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to evaluate the model it can be switched to `eval` state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    output_list = []\n",
    "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
    "        if three_inputs_mode:\n",
    "            batch = [\n",
    "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
    "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
    "                torch.tensor(batch_x['Categorical'])\n",
    "            ]\n",
    "        else:\n",
    "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
    "\n",
    "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
    "        \n",
    "        output_list.append((list(batch_pred), list(batch_y)))\n",
    "        \n",
    "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
    "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
    "        num_samples += len(batch_y)\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
    "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
    "    \n",
    "\n",
    "    batch_pred = [c for x in output_list for c in x[0]]\n",
    "    batch_y = [c for x in output_list for c in x[1]]\n",
    "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
    "    output_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission(model, data_for_autotest, name='Submission')\n",
    "print('Submission file generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Both the notebook and the `.py` file are required to submit this homework.__"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNN_for_texts.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
